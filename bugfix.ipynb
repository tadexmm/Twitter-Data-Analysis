{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09b8563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load extract_dataframe.py\n",
    "import json\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "import re\n",
    "\n",
    "def read_json(json_file: str)->list:\n",
    "    \"\"\"\n",
    "    json file reader to open and read json files into a list\n",
    "    Args:\n",
    "    -----\n",
    "    json_file: str - path of a json file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    length of the json file and a list of json\n",
    "    \"\"\"\n",
    "    \n",
    "    tweets_data = []\n",
    "    for tweets in open(json_file,'r'):\n",
    "        tweets_data.append(json.loads(tweets))\n",
    "    \n",
    "    \n",
    "    return len(tweets_data), tweets_data\n",
    "\n",
    "class TweetDfExtractor:\n",
    "    \"\"\"\n",
    "    this function will parse tweets json into a pandas dataframe\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    dataframe\n",
    "    \"\"\"\n",
    "    def __init__(self, tweets_list):\n",
    "        \n",
    "        self.tweets_list = tweets_list\n",
    "\n",
    "    # an example function\n",
    "    def find_statuses_count(self)->list:\n",
    "        statuses_count = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                statuses_count.append(x['user']['statuses_count'])\n",
    "            except KeyError:\n",
    "                statuses_count.append(None)\n",
    "            \n",
    "        return statuses_count\n",
    "        \n",
    "    def find_full_text(self)->list:\n",
    "        full_text = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                full_text.append(x['full_text'])\n",
    "            except KeyError:\n",
    "                full_text.append(None)\n",
    "            \n",
    "        return full_text\n",
    "\n",
    "    def clean_original_text(self, original_text):\n",
    "        # Make lower case\n",
    "        clean_text = []\n",
    "        punctuation = string.punctuation.replace('@', \"\")\n",
    "        punctuation = punctuation.replace('_', \"\")\n",
    "        \n",
    "        for x in original_text:\n",
    "            c = x.lower()\n",
    "            c = c.replace('\\n', '')\n",
    "            c = c.translate(str.maketrans(\" \", \" \", punctuation))\n",
    "            c = re.sub('@[\\w]+', ' ', c)\n",
    "            c = c.translate(str.maketrans(\" \", \" \", punctuation))\n",
    "            clean_text.append(c)\n",
    "        return clean_text\n",
    "    \n",
    "    def find_screen_count(self):\n",
    "        screen_count = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                screen_count.append(x['user']['listed_count'])\n",
    "            except KeyError:\n",
    "                screen_count.append(None)\n",
    "            \n",
    "        return screen_count\n",
    "        \n",
    "    def find_place(self):\n",
    "        place = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                place.append(x['place'][\"name\"])\n",
    "            except TypeError:\n",
    "                place.append(None)\n",
    "            \n",
    "        return place\n",
    "\n",
    "    def find_place_coord_boundaries(self):\n",
    "        place = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                place.append(x['place'][\"bounding_box\"][\"coordinates\"])\n",
    "            except TypeError:\n",
    "                place.append(None)\n",
    "            \n",
    "        return place\n",
    "    \n",
    "    def find_place_country(self):\n",
    "        place = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                place.append(x['place'][\"country\"])\n",
    "            except TypeError:\n",
    "                place.append(None)\n",
    "\n",
    "        return place\n",
    "\n",
    "    def self_find_place_country(self):\n",
    "        lang = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                lang.append(x['lang'])\n",
    "            except KeyError:\n",
    "                lang.append(None)\n",
    "            \n",
    "        return lang\n",
    "\n",
    "    def find_sentiments(self, text)->list:\n",
    "        polarity = []\n",
    "        subjectivity = []\n",
    "        for x in text:\n",
    "            t = TextBlob(x)\n",
    "            polarity.append(t.polarity)\n",
    "            subjectivity.append(t.subjectivity)\n",
    "            \n",
    "        return polarity, subjectivity\n",
    "\n",
    "    def find_lang(self)->list:\n",
    "        lang = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                lang.append(x['lang'])\n",
    "            except KeyError:\n",
    "                lang.append(None)\n",
    "            \n",
    "        return lang\n",
    "        \n",
    "    def find_created_time(self)->list:\n",
    "        created_at = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                created_at.append(x['created_at'])\n",
    "            except KeyError:\n",
    "                created_at.append(None)\n",
    "            \n",
    "        return created_at\n",
    "\n",
    "    def find_source(self)->list:\n",
    "        source = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                s = x['source']\n",
    "                source.append(s[s.find(\">\")+1:s.rfind(\"<\")])\n",
    "            except KeyError:\n",
    "                source.append(None)\n",
    "            \n",
    "        return source\n",
    "\n",
    "    def find_screen_name(self)->list:\n",
    "        screen_name = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                screen_name.append(x['user']['screen_name'])\n",
    "            except KeyError:\n",
    "                screen_name.append(None)\n",
    "            \n",
    "        return screen_name\n",
    "\n",
    "    def find_followers_count(self)->list:\n",
    "        followers_count = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                followers_count.append(x['user']['followers_count'])\n",
    "            except KeyError:\n",
    "                followers_count.append(None)\n",
    "            \n",
    "        return followers_count\n",
    "\n",
    "    def find_friends_count(self)->list:\n",
    "        friends_count = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                friends_count.append(x['user']['friends_count'])\n",
    "            except KeyError:\n",
    "                friends_count.append(None)\n",
    "            \n",
    "        return friends_count\n",
    "\n",
    "    def is_sensitive(self)->list:\n",
    "        is_sensitive = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                is_sensitive.append(x['possibly_sensitive'])\n",
    "            except KeyError:\n",
    "                is_sensitive.append(None)\n",
    "            \n",
    "        return is_sensitive\n",
    "\n",
    "    def find_favourite_count(self)->list:\n",
    "        favorite_count = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                favorite_count.append(x['favorite_count'])\n",
    "            except KeyError:\n",
    "                favorite_count.append(None)\n",
    "            \n",
    "        return favorite_count\n",
    "    \n",
    "    def find_retweet_count(self)->list:\n",
    "        retweet_count = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                retweet_count.append(x['retweet_count'])\n",
    "            except KeyError:\n",
    "                retweet_count.append(None)\n",
    "            \n",
    "        return retweet_count\n",
    "\n",
    "    def find_hashtags(self)->list:\n",
    "        hashtags = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                hashtags.append(\" \".join([y[\"text\"] for y in x['entities']['hashtags']]))\n",
    "            except KeyError:\n",
    "                hashtags.append(None)\n",
    "            \n",
    "        return hashtags\n",
    "\n",
    "    def find_mentions(self)->list:\n",
    "        user_mentions = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                user_mentions.append(len(x['entities']['user_mentions']))\n",
    "            except KeyError:\n",
    "                user_mentions.append(None)\n",
    "            \n",
    "        return user_mentions\n",
    "\n",
    "\n",
    "    def find_user_location(self)->list:\n",
    "        location = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                l = x['user']['location']\n",
    "                if l.strip() == \"\":\n",
    "                    location.append(None)\n",
    "                else:\n",
    "                    location.append(l)\n",
    "            except TypeError:\n",
    "                location.append(None)\n",
    "            \n",
    "        return location\n",
    "        \n",
    "    def get_tweet_df(self, save=False)->pd.DataFrame:\n",
    "        \"\"\"required column to be generated you should be creative and add more features\"\"\"\n",
    "        \n",
    "        # columns = ['created_at', 'source', 'original_text','polarity','subjectivity', 'lang', 'favorite_count', 'retweet_count',\n",
    "        #           'original_author', 'followers_count','friends_count','possibly_sensitive', 'hashtags', 'user_mentions', 'place']\n",
    "        columns = ['created_at', 'source', 'original_text','clean_text', 'sentiment','polarity','subjectivity',\n",
    "                   'lang', 'favorite_count', 'retweet_count', 'original_author', 'user_location', 'screen_count',\n",
    "                   'followers_count','friends_count','possibly_sensitive', 'hashtags', 'user_mentions',\n",
    "                   'place', 'place_coord_boundaries', 'place_country']\n",
    "        created_at = self.find_created_time()\n",
    "        source = self.find_source()\n",
    "        original_text = self.find_full_text()\n",
    "        clean_text = self.clean_original_text(original_text)\n",
    "        polarity, subjectivity = self.find_sentiments(clean_text)\n",
    "        sentiment = zip(polarity, subjectivity)\n",
    "        lang = self.find_lang()\n",
    "        favorite_count = self.find_favourite_count()\n",
    "        retweet_count = self.find_retweet_count()\n",
    "        original_author = self.find_screen_name()\n",
    "        user_location = self.find_user_location()\n",
    "        screen_count = self.find_screen_count()\n",
    "        followers_count = self.find_followers_count()\n",
    "        friends_count = self.find_friends_count()\n",
    "        possibly_sensitive = self.is_sensitive()\n",
    "        hashtags = self.find_hashtags()\n",
    "        user_mentions = self.find_mentions()\n",
    "        #location = self.find_location()\n",
    "        place = self.find_place()\n",
    "        place_coord_boundaries = self.find_place_coord_boundaries()\n",
    "        place_country = self.find_place_country()\n",
    "\n",
    "        data = zip(created_at, source, original_text, clean_text, sentiment, polarity, subjectivity, lang,\n",
    "                   favorite_count, retweet_count, original_author, user_location, screen_count,\n",
    "                   followers_count, friends_count, possibly_sensitive, hashtags, user_mentions, place\n",
    "                   , place_coord_boundaries, place_country)\n",
    "        df = pd.DataFrame(data=data, columns=columns)\n",
    "\n",
    "        if save:\n",
    "            df.to_csv('processed_tweet_data.csv', index=False)\n",
    "            print('File Successfully Saved.!!!')\n",
    "        \n",
    "        return df\n",
    "\n",
    "                \n",
    "if __name__ == \"__main__\":\n",
    "    # required column to be generated you should be creative and add more features\n",
    "    columns = ['created_at', 'source', 'original_text','clean_text', 'sentiment','polarity','subjectivity', 'lang', 'favorite_count', 'retweet_count', \n",
    "    'original_author', 'screen_count', 'followers_count','friends_count','possibly_sensitive', 'hashtags', 'user_mentions', 'place', 'place_coord_boundaries']\n",
    "    _, tweet_list = read_json(\"data/global_twitter_data.json\")\n",
    "    tweet = TweetDfExtractor(tweet_list)\n",
    "    tweet_df = tweet.get_tweet_df() \n",
    "\n",
    "    # use all defined functions to generate a dataframe with the specified columns above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2189d538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<method 'translate' of 'str' objects>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str.translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "592bcc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22000 entries, 0 to 21999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   created_at              22000 non-null  object \n",
      " 1   source                  22000 non-null  object \n",
      " 2   original_text           22000 non-null  object \n",
      " 3   clean_text              22000 non-null  object \n",
      " 4   sentiment               22000 non-null  object \n",
      " 5   polarity                22000 non-null  float64\n",
      " 6   subjectivity            22000 non-null  float64\n",
      " 7   lang                    22000 non-null  object \n",
      " 8   favorite_count          22000 non-null  int64  \n",
      " 9   retweet_count           22000 non-null  int64  \n",
      " 10  original_author         22000 non-null  object \n",
      " 11  user_location           12106 non-null  object \n",
      " 12  screen_count            22000 non-null  int64  \n",
      " 13  followers_count         22000 non-null  int64  \n",
      " 14  friends_count           22000 non-null  int64  \n",
      " 15  possibly_sensitive      6191 non-null   object \n",
      " 16  hashtags                22000 non-null  object \n",
      " 17  user_mentions           22000 non-null  int64  \n",
      " 18  place                   117 non-null    object \n",
      " 19  place_coord_boundaries  117 non-null    object \n",
      " 20  place_country           117 non-null    object \n",
      "dtypes: float64(2), int64(6), object(13)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "tweet_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e6d42f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    rt   extra random image ilets focus in one ver...\n",
      "1    rt   chinas media explains the military reason...\n",
      "2    china even cut off communication they dont anw...\n",
      "3    putin to xijinping  i told you my friend taiwa...\n",
      "4    rt   i’m sorry i thought taiwan was an indepen...\n",
      "Name: clean_text, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    RT @i_ameztoy: Extra random image (I):\\n\\nLets...\n",
       "1    RT @IndoPac_Info: #China's media explains the ...\n",
       "2    China even cut off communication, they don't a...\n",
       "3    Putin to #XiJinping : I told you my friend, Ta...\n",
       "4    RT @ChinaUncensored: I’m sorry, I thought Taiw...\n",
       "Name: original_text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(str(tweet_df.head()[\"clean_text\"]))\n",
    "tweet_df.head()[\"original_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70dd6241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load clean_tweets_dataframe.py\n",
    "import pandas as pd\n",
    "\n",
    "class Clean_Tweets:\n",
    "    \"\"\"\n",
    "    The PEP8 Standard AMAZING!!!\n",
    "    \"\"\"\n",
    "    def __init__(self, df:pd.DataFrame):\n",
    "        self.df = df\n",
    "        print('Automation in Action...!!!')\n",
    "        \n",
    "    def drop_unwanted_column(self, df:pd.DataFrame)->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        remove rows that has column names. This error originated from\n",
    "        the data collection stage.  \n",
    "        \"\"\"\n",
    "        unwanted_rows = df[df['retweet_count'] == 'retweet_count' ].index\n",
    "        df.drop(unwanted_rows , inplace=True)\n",
    "        df = df[df['polarity'] != 'polarity']\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def drop_duplicate(self, df:pd.DataFrame)->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        drop duplicate rows\n",
    "        \"\"\"\n",
    "        df.drop_duplicates()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def convert_to_datetime(self, df:pd.DataFrame)->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        convert column to datetime\n",
    "        \"\"\"\n",
    "        df[\"created_at\"] = pd.to_datetime(df[\"created_at\"], infer_datetime_format=True)\n",
    "        df = df[df['created_at'] >= '2020-12-31' ]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def convert_to_numbers(self, df:pd.DataFrame)->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        convert columns like polarity, subjectivity, retweet_count\n",
    "        favorite_count etc to numbers\n",
    "        \"\"\"\n",
    "        \n",
    "        integer_columns = [\"retweet_count\", \"followers_count\", \"friends_count\", \"user_mentions\"]\n",
    "        float_columns = [\"polarity\", \"subjectivity\"]\n",
    "        \n",
    "        df[integer_columns] = df[integer_columns].astype(int)\n",
    "        df[float_columns] = df[float_columns].astype(float)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def remove_non_english_tweets(self, df:pd.DataFrame)->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        remove non english tweets from lang\n",
    "        \"\"\"\n",
    "        mask = df[\"lang\"] == \"en\"\n",
    "        df = df[mask]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def remove_retweets(self, df:pd.DataFrame)->pd.DataFrame:\n",
    "        mask = df[\"original_text\"].str.contains(\"^RT\")\n",
    "        df = df[~mask]\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2929647b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automation in Action...!!!\n"
     ]
    }
   ],
   "source": [
    "c = Clean_Tweets(tweet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e1f2bd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4736 entries, 2 to 21997\n",
      "Data columns (total 20 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   created_at              4736 non-null   object \n",
      " 1   source                  4736 non-null   object \n",
      " 2   original_text           4736 non-null   object \n",
      " 3   clean_text              4736 non-null   object \n",
      " 4   sentiment               4736 non-null   object \n",
      " 5   polarity                4736 non-null   float64\n",
      " 6   subjectivity            4736 non-null   float64\n",
      " 7   lang                    4736 non-null   object \n",
      " 8   favorite_count          4736 non-null   int64  \n",
      " 9   retweet_count           4736 non-null   int64  \n",
      " 10  original_author         4736 non-null   object \n",
      " 11  screen_count            4736 non-null   int64  \n",
      " 12  followers_count         4736 non-null   int64  \n",
      " 13  friends_count           4736 non-null   int64  \n",
      " 14  possibly_sensitive      3468 non-null   object \n",
      " 15  hashtags                4736 non-null   object \n",
      " 16  user_mentions           4736 non-null   int64  \n",
      " 17  place                   117 non-null    object \n",
      " 18  place_coord_boundaries  117 non-null    object \n",
      " 19  place_country           117 non-null    object \n",
      "dtypes: float64(2), int64(6), object(12)\n",
      "memory usage: 777.0+ KB\n"
     ]
    }
   ],
   "source": [
    "tweet_df[\"created_at\"]\n",
    "c.remove_retweets(tweet_df).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3202cc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
