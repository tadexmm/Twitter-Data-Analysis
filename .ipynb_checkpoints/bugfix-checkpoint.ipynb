{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d09b8563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load extract_dataframe.py\n",
    "import json\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "def read_json(json_file: str)->list:\n",
    "    \"\"\"\n",
    "    json file reader to open and read json files into a list\n",
    "    Args:\n",
    "    -----\n",
    "    json_file: str - path of a json file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    length of the json file and a list of json\n",
    "    \"\"\"\n",
    "    \n",
    "    tweets_data = []\n",
    "    for tweets in open(json_file,'r'):\n",
    "        tweets_data.append(json.loads(tweets))\n",
    "    \n",
    "    \n",
    "    return len(tweets_data), tweets_data\n",
    "\n",
    "class TweetDfExtractor:\n",
    "    \"\"\"\n",
    "    this function will parse tweets json into a pandas dataframe\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    dataframe\n",
    "    \"\"\"\n",
    "    def __init__(self, tweets_list):\n",
    "        \n",
    "        self.tweets_list = tweets_list\n",
    "\n",
    "    # an example function\n",
    "    def find_statuses_count(self)->list:\n",
    "        statuses_count = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                statuses_count.append(x['user']['statuses_count'])\n",
    "            except KeyError:\n",
    "                statuses_count.append(None)\n",
    "            \n",
    "        return statuses_count\n",
    "        \n",
    "    def find_full_text(self)->list:\n",
    "        full_text = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                full_text.append(x['full_text'])\n",
    "            except KeyError:\n",
    "                full_text.append(None)\n",
    "            \n",
    "        return full_text\n",
    "       \n",
    "    \n",
    "    def find_sentiments(self, text)->list:\n",
    "        polarity = []\n",
    "        subjectivity = []\n",
    "        for x in text:\n",
    "            t = TextBlob(x)\n",
    "            polarity.append(t.polarity)\n",
    "            subjectivity.append(t.subjectivity)\n",
    "            \n",
    "        return polarity, subjectivity\n",
    "\n",
    "    def find_lang(self)->list:\n",
    "        lang = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                lang.append(x['lang'])\n",
    "            except KeyError:\n",
    "                lang.append(None)\n",
    "            \n",
    "        return lang\n",
    "        \n",
    "    def find_created_time(self)->list:\n",
    "        created_at = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                created_at.append(x['created_at'])\n",
    "            except KeyError:\n",
    "                created_at.append(None)\n",
    "            \n",
    "        return created_at\n",
    "\n",
    "    def find_source(self)->list:\n",
    "        source = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                source.append(x['source'])\n",
    "            except KeyError:\n",
    "                source.append(None)\n",
    "            \n",
    "        return source\n",
    "\n",
    "    def find_screen_name(self)->list:\n",
    "        screen_name = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                screen_name.append(x['user']['screen_name'])\n",
    "            except KeyError:\n",
    "                screen_name.append(None)\n",
    "            \n",
    "        return screen_name\n",
    "\n",
    "    def find_followers_count(self)->list:\n",
    "        followers_count = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                followers_count.append(x['user']['followers_count'])\n",
    "            except KeyError:\n",
    "                followers_count.append(None)\n",
    "            \n",
    "        return followers_count\n",
    "\n",
    "    def find_friends_count(self)->list:\n",
    "        friends_count = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                friends_count.append(x['user']['friends_count'])\n",
    "            except KeyError:\n",
    "                friends_count.append(None)\n",
    "            \n",
    "        return friends_count\n",
    "\n",
    "    def is_sensitive(self)->list:\n",
    "        is_sensitive = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                is_sensitive.append(x['possibly_sensitive'])\n",
    "            except KeyError:\n",
    "                is_sensitive.append(None)\n",
    "            \n",
    "        return is_sensitive\n",
    "\n",
    "    def find_favourite_count(self)->list:\n",
    "        favorite_count = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                favorite_count.append(x['favorite_count'])\n",
    "            except KeyError:\n",
    "                favorite_count.append(None)\n",
    "            \n",
    "        return favorite_count\n",
    "    \n",
    "    def find_retweet_count(self)->list:\n",
    "        retweet_count = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                retweet_count.append(x['retweet_count'])\n",
    "            except KeyError:\n",
    "                retweet_count.append(None)\n",
    "            \n",
    "        return retweet_count\n",
    "\n",
    "    def find_hashtags(self)->list:\n",
    "        hashtags = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                hashtags.append([y[\"text\"] for y in x['entities']['hashtags']])\n",
    "            except KeyError:\n",
    "                hashtags.append(None)\n",
    "            \n",
    "        return hashtags\n",
    "\n",
    "    def find_mentions(self)->list:\n",
    "        user_mentions = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                user_mentions.append(len(x['entities']['user_mentions']))\n",
    "            except KeyError:\n",
    "                user_mentions.append(None)\n",
    "            \n",
    "        return user_mentions\n",
    "\n",
    "\n",
    "    def find_location(self)->list:\n",
    "        location = []\n",
    "        for x in self.tweets_list:\n",
    "            try:\n",
    "                location.append(x['user']['location'])\n",
    "            except TypeError:\n",
    "                location.append('')\n",
    "            \n",
    "        return location\n",
    "        \n",
    "    def get_tweet_df(self, save=False)->pd.DataFrame:\n",
    "        \"\"\"required column to be generated you should be creative and add more features\"\"\"\n",
    "        \n",
    "        columns = ['created_at', 'source', 'original_text','polarity','subjectivity', 'lang', 'favorite_count', 'retweet_count', \n",
    "            'original_author', 'followers_count','friends_count','possibly_sensitive', 'hashtags', 'user_mentions', 'place']\n",
    "        \n",
    "        created_at = self.find_created_time()\n",
    "        source = self.find_source()\n",
    "        text = self.find_full_text()\n",
    "        polarity, subjectivity = self.find_sentiments(text)\n",
    "        lang = self.find_lang()\n",
    "        fav_count = self.find_favourite_count()\n",
    "        retweet_count = self.find_retweet_count()\n",
    "        screen_name = self.find_screen_name()\n",
    "        follower_count = self.find_followers_count()\n",
    "        friends_count = self.find_friends_count()\n",
    "        sensitivity = self.is_sensitive()\n",
    "        hashtags = self.find_hashtags()\n",
    "        mentions = self.find_mentions()\n",
    "        location = self.find_location()\n",
    "\n",
    "        data = zip(created_at, source, text, polarity, subjectivity, lang, fav_count, retweet_count, screen_name, follower_count, friends_count, sensitivity, hashtags, mentions, location)\n",
    "        df = pd.DataFrame(data=data, columns=columns)\n",
    "\n",
    "        if save:\n",
    "            df.to_csv('processed_tweet_data.csv', index=False)\n",
    "            print('File Successfully Saved.!!!')\n",
    "        \n",
    "        return df\n",
    "\n",
    "                \n",
    "if __name__ == \"__main__\":\n",
    "    # required column to be generated you should be creative and add more features\n",
    "    columns = ['created_at', 'source', 'original_text','clean_text', 'sentiment','polarity','subjectivity', 'lang', 'favorite_count', 'retweet_count', \n",
    "    'original_author', 'screen_count', 'followers_count','friends_count','possibly_sensitive', 'hashtags', 'user_mentions', 'place', 'place_coord_boundaries']\n",
    "    _, tweet_list = read_json(\"data/africa_twitter_data.json\")\n",
    "    tweet = TweetDfExtractor(tweet_list)\n",
    "    tweet_df = tweet.get_tweet_df() \n",
    "\n",
    "    # use all defined functions to generate a dataframe with the specified columns above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7e6d42f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "      <th>original_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>lang</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>original_author</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed Aug 03 20:19:13 +0000 2022</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>#Pelosi airplane landed safely in #Taiwan üáπüáº  ...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.203571</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DzCritical</td>\n",
       "      <td>318</td>\n",
       "      <td>373</td>\n",
       "      <td>None</td>\n",
       "      <td>[Pelosi, Taiwan, NATO, 5G]</td>\n",
       "      <td>0</td>\n",
       "      <td>Alg√©rie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tue Aug 02 15:24:42 +0000 2022</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>Watch the video of the beginning of the Chines...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>toopsat</td>\n",
       "      <td>764</td>\n",
       "      <td>144</td>\n",
       "      <td>False</td>\n",
       "      <td>[Pelosi, „Éû„ÉÑ„Ç≥„ÅÆÁü•„Çâ„Å™„ÅÑ‰∏ñÁïå, Yediiklim, BadDecisionsTr...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue Aug 02 15:02:35 +0000 2022</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>#Pelosi \\n#Taipei \\n#taiwan\\n#XiJinping \\n#Chi...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NassimaLilEmy</td>\n",
       "      <td>64</td>\n",
       "      <td>47</td>\n",
       "      <td>False</td>\n",
       "      <td>[Pelosi, Taipei, taiwan, XiJinping, China]</td>\n",
       "      <td>0</td>\n",
       "      <td>Alg√©rie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon Aug 01 13:51:42 +0000 2022</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>#HOBIPALOOZA #LaAcademiaExpulsion #WEURO2022 #...</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_dhayae</td>\n",
       "      <td>60</td>\n",
       "      <td>463</td>\n",
       "      <td>False</td>\n",
       "      <td>[HOBIPALOOZA, LaAcademiaExpulsion, WEURO2022, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Chlef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun Jul 31 20:02:20 +0000 2022</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>#Pelosi\\n#china\\nChina Time ‚úåÔ∏è https://t.co/tE...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Mohamme65404115</td>\n",
       "      <td>39</td>\n",
       "      <td>206</td>\n",
       "      <td>False</td>\n",
       "      <td>[Pelosi, china]</td>\n",
       "      <td>0</td>\n",
       "      <td>Alg√©rie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28603</th>\n",
       "      <td>Tue Aug 02 14:40:31 +0000 2022</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>Final approach to Taipei\\n#Pelosi #SPAR19 http...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AndStrats</td>\n",
       "      <td>1136</td>\n",
       "      <td>574</td>\n",
       "      <td>False</td>\n",
       "      <td>[Pelosi, SPAR19]</td>\n",
       "      <td>0</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28604</th>\n",
       "      <td>Tue Aug 02 13:25:42 +0000 2022</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>#SPAR19 getting closer #Taiwan #NANCY_PELOSI I...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>jen_mazzei</td>\n",
       "      <td>40</td>\n",
       "      <td>162</td>\n",
       "      <td>False</td>\n",
       "      <td>[SPAR19, Taiwan, NANCY_PELOSI]</td>\n",
       "      <td>0</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28605</th>\n",
       "      <td>Tue Aug 02 13:08:29 +0000 2022</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>#SPAR19 is heading directly to #Taiwan let‚Äôs h...</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>jen_mazzei</td>\n",
       "      <td>40</td>\n",
       "      <td>162</td>\n",
       "      <td>False</td>\n",
       "      <td>[SPAR19, Taiwan, ww3]</td>\n",
       "      <td>0</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28606</th>\n",
       "      <td>Tue Aug 02 13:03:37 +0000 2022</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>#SPAR19 prayers that China doesn‚Äôt overreact f...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>jen_mazzei</td>\n",
       "      <td>40</td>\n",
       "      <td>162</td>\n",
       "      <td>False</td>\n",
       "      <td>[SPAR19, nancypelosi, Taiwan]</td>\n",
       "      <td>0</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28607</th>\n",
       "      <td>Sun Jul 31 18:50:59 +0000 2022</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>Where is Paul #Pelosi today?\\n\\nAsking for a f...</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AndStrats</td>\n",
       "      <td>1136</td>\n",
       "      <td>574</td>\n",
       "      <td>None</td>\n",
       "      <td>[Pelosi]</td>\n",
       "      <td>0</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28608 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           created_at  \\\n",
       "0      Wed Aug 03 20:19:13 +0000 2022   \n",
       "1      Tue Aug 02 15:24:42 +0000 2022   \n",
       "2      Tue Aug 02 15:02:35 +0000 2022   \n",
       "3      Mon Aug 01 13:51:42 +0000 2022   \n",
       "4      Sun Jul 31 20:02:20 +0000 2022   \n",
       "...                               ...   \n",
       "28603  Tue Aug 02 14:40:31 +0000 2022   \n",
       "28604  Tue Aug 02 13:25:42 +0000 2022   \n",
       "28605  Tue Aug 02 13:08:29 +0000 2022   \n",
       "28606  Tue Aug 02 13:03:37 +0000 2022   \n",
       "28607  Sun Jul 31 18:50:59 +0000 2022   \n",
       "\n",
       "                                                  source  \\\n",
       "0      <a href=\"http://twitter.com/download/android\" ...   \n",
       "1      <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
       "2      <a href=\"http://twitter.com/download/android\" ...   \n",
       "3      <a href=\"http://twitter.com/download/android\" ...   \n",
       "4      <a href=\"http://twitter.com/download/android\" ...   \n",
       "...                                                  ...   \n",
       "28603  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
       "28604  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "28605  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "28606  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "28607  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
       "\n",
       "                                           original_text  polarity  \\\n",
       "0      #Pelosi airplane landed safely in #Taiwan üáπüáº  ...  0.300000   \n",
       "1      Watch the video of the beginning of the Chines...  0.000000   \n",
       "2      #Pelosi \\n#Taipei \\n#taiwan\\n#XiJinping \\n#Chi...  0.000000   \n",
       "3      #HOBIPALOOZA #LaAcademiaExpulsion #WEURO2022 #...  0.433333   \n",
       "4      #Pelosi\\n#china\\nChina Time ‚úåÔ∏è https://t.co/tE...  0.000000   \n",
       "...                                                  ...       ...   \n",
       "28603  Final approach to Taipei\\n#Pelosi #SPAR19 http...  0.000000   \n",
       "28604  #SPAR19 getting closer #Taiwan #NANCY_PELOSI I...  0.000000   \n",
       "28605  #SPAR19 is heading directly to #Taiwan let‚Äôs h...  0.225000   \n",
       "28606  #SPAR19 prayers that China doesn‚Äôt overreact f...  0.000000   \n",
       "28607  Where is Paul #Pelosi today?\\n\\nAsking for a f... -0.200000   \n",
       "\n",
       "       subjectivity lang  favorite_count  retweet_count  original_author  \\\n",
       "0          0.203571   en               0              0       DzCritical   \n",
       "1          0.000000   en               3              0          toopsat   \n",
       "2          0.000000   en               2              0    NassimaLilEmy   \n",
       "3          0.733333   en               0              0         d_dhayae   \n",
       "4          0.000000   en               2              0  Mohamme65404115   \n",
       "...             ...  ...             ...            ...              ...   \n",
       "28603      1.000000   en               1              1        AndStrats   \n",
       "28604      0.000000   en               8              0       jen_mazzei   \n",
       "28605      0.525000   en               3              2       jen_mazzei   \n",
       "28606      0.000000   en               2              0       jen_mazzei   \n",
       "28607      0.100000   en               0              0        AndStrats   \n",
       "\n",
       "       followers_count  friends_count possibly_sensitive  \\\n",
       "0                  318            373               None   \n",
       "1                  764            144              False   \n",
       "2                   64             47              False   \n",
       "3                   60            463              False   \n",
       "4                   39            206              False   \n",
       "...                ...            ...                ...   \n",
       "28603             1136            574              False   \n",
       "28604               40            162              False   \n",
       "28605               40            162              False   \n",
       "28606               40            162              False   \n",
       "28607             1136            574               None   \n",
       "\n",
       "                                                hashtags  user_mentions  \\\n",
       "0                             [Pelosi, Taiwan, NATO, 5G]              0   \n",
       "1      [Pelosi, „Éû„ÉÑ„Ç≥„ÅÆÁü•„Çâ„Å™„ÅÑ‰∏ñÁïå, Yediiklim, BadDecisionsTr...              0   \n",
       "2             [Pelosi, Taipei, taiwan, XiJinping, China]              0   \n",
       "3      [HOBIPALOOZA, LaAcademiaExpulsion, WEURO2022, ...              0   \n",
       "4                                        [Pelosi, china]              0   \n",
       "...                                                  ...            ...   \n",
       "28603                                   [Pelosi, SPAR19]              0   \n",
       "28604                     [SPAR19, Taiwan, NANCY_PELOSI]              0   \n",
       "28605                              [SPAR19, Taiwan, ww3]              0   \n",
       "28606                      [SPAR19, nancypelosi, Taiwan]              0   \n",
       "28607                                           [Pelosi]              0   \n",
       "\n",
       "                                place  \n",
       "0                             Alg√©rie  \n",
       "1                                      \n",
       "2                             Alg√©rie  \n",
       "3      Chlef                           \n",
       "4                             Alg√©rie  \n",
       "...                               ...  \n",
       "28603                              VA  \n",
       "28604                              VA  \n",
       "28605                              VA  \n",
       "28606                              VA  \n",
       "28607                              VA  \n",
       "\n",
       "[28608 rows x 15 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feedb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load data/global_twitter_data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "704fe0b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1616897506.py, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [81]\u001b[1;36m\u001b[0m\n\u001b[1;33m    ---\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# %load clean_tweets_dataframe.py\n",
    "class Clean_Tweets:\n",
    "    \"\"\"\n",
    "    The PEP8 Standard AMAZING!!!\n",
    "    \"\"\"\n",
    "    def __init__(self, df:pd.DataFrame):\n",
    "        self.df = df\n",
    "        print('Automation in Action...!!!')\n",
    "        \n",
    "    def drop_unwanted_column(self, df:pd.DataFrame)->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        remove rows that has column names. This error originated from\n",
    "        the data collection stage.  \n",
    "        \"\"\"\n",
    "        unwanted_rows = df[df['retweet_count'] == 'retweet_count' ].index\n",
    "        df.drop(unwanted_rows , inplace=True)\n",
    "        df = df[df['polarity'] != 'polarity']\n",
    "        \n",
    "        return df\n",
    "    def drop_duplicate(self, df:pd.DataFrame)->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        drop duplicate rows\n",
    "        \"\"\"\n",
    "        \n",
    "        ---\n",
    "        \n",
    "        return df\n",
    "    def convert_to_datetime(self, df:pd.DataFrame)->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        convert column to datetime\n",
    "        \"\"\"\n",
    "        ----\n",
    "        \n",
    "        ----\n",
    "        \n",
    "        df = df[df['created_at'] >= '2020-12-31' ]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def convert_to_numbers(self, df:pd.DataFrame)->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        convert columns like polarity, subjectivity, retweet_count\n",
    "        favorite_count etc to numbers\n",
    "        \"\"\"\n",
    "        df['polarity'] = pd.----\n",
    "        \n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def remove_non_english_tweets(self, df:pd.DataFrame)->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        remove non english tweets from lang\n",
    "        \"\"\"\n",
    "        \n",
    "        df = ----\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dd6241",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
